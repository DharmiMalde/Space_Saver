# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R0yvWd9PNdLLzL_2uD2EhgLpdiZZQ2de
"""

#Spazer tool for processing web pages
#

from bs4 import BeautifulSoup
import pathlib
import re

#Variables to track the input, output and gained space
space_gained = 0
space_input = 0
space_output = 0

print("Welcome to Spazer\n")

for x in range(5):
    filename = str(x) + ".html"
    file = pathlib.Path('/content/drive/MyDrive/space saver/input/' + filename)
    if (file.exists()):

        #Read each file
        print("Reading " + filename)
        f = open('/content/drive/MyDrive/space saver/input/' + filename, 'r', errors="ignore")
        contents = f.read()

        #Remove html tags
        soup = BeautifulSoup(contents, 'lxml')
        output = soup.get_text()

        # removing the words which are at large distance from commas
        words = output.split()
        output1 = []
        comma_indices = [i for i, word in enumerate(words) if ',' in word]
        end_index = 0
        for i in comma_indices:
          start_index = max(0, i - 5,end_index)
          end_index = start_index + 15
          output1 = output1[:start_index] + words[start_index:end_index]
        output = ' '.join(output1)

        ## 4 words at a time removing the non capitals
        def process_text(text):
          words = text.split()
          result_words = []

          for i in range(0, len(words), 4):
              # Extract the current 4 words
              current_words = words[i:i+4]

              # Check if all four words have first letters capitalized
              if any(word.istitle() for word in current_words):
                  result_words.extend(current_words)

          return ' '.join(result_words)

          output = process_text(output)

          # Removing stop words
          stop_words=['more', 'just', 'she', 'y', 'yourselves', 'until', "isn't", 'but', 'if', 'are', 'as', "mustn't", 'own', 'whom', 'not', "aren't", 'hadn',
            'aren', 'about', 'the', 'that', 'him', 'below', 'yourself', 'll', 're', 'hasn', 'couldn', "that'll", 'why', 'didn', 'is', 'been', 'who',
            'hers', 'other', 'weren', 'then', 'shouldn', "you're", 'no', 'itself', 'isn', 'yours', "needn't", 'to', 'this', 'between', 'now', 'they',
            'under', 'our', 'did', 'because', 'a', 'both', 'against', 'will', 'don', "don't", 'won', 't', 'how', 'my', "you've", "wouldn't", 'where', 'their',
            'few', 'do', 'after', "she's", 'ain', 'of', 'mustn', 'can', 'up', 'ourselves', 'them', 'nor', 'before', 'you', 'when', "wasn't", 'your', 'for',
            'or', 'from', 'does', 'very', 's', 'over', 'doesn', 'all', 'myself', "weren't", 'some', 'theirs', 'in', 'wasn', 'which', 'he', 'his', 'her', "it's",
            'ours', "should've", 'd', "hadn't", 'we', 'having', 'an', 've', 'me', 'wouldn', 'too', "you'd", 'should', 'am', 'it', 'each', 'above', 'during',
            'further', 'only', 'again', 'on', 'has', 'shan', "hasn't", 'these', 'out', "shan't", "mightn't", 'such', 'by', 'have', "doesn't", "haven't", 'had',
            'and', "didn't", 'm', 'be', 'any', 'those', 'same', 'while', 'mightn', "couldn't", 'was', 'were', 'off', 'ma', 'herself', 'so', 'most', 'needn', 'into',
            'doing', 'himself', 'themselves', 'haven', 'through', 'at', 'with', 'there', 'down', 'its', 'i', "shouldn't", "won't", "you'll", 'what', 'o', 'here', 'once',
            'than', 'being']

          word_tokens = output.split()
          filtered_words = [w for w in word_tokens if not w.lower() in stop_words]
          output = " ".join(map(str, filtered_words))

        #Your code ends  #################################

        #Write the output variable contents to output/ folder.
        print ("Writing reduced " + filename)
        fw = open('/content/drive/MyDrive/space saver/output/' + filename, "w")
        fw.write(output)
        fw.close()
        f.close()

        #Calculate space savings
        space_input = space_input + len(contents)
        space_output = space_output + len(output)

space_gained = round((space_input - space_output) * 100 / space_input, 2)

print("\nTotal Space used by input files = " + str(space_input) + " characters.")
print("Total Space used by output files = " + str(space_output) + " characters.")
print("Total Space Gained = " + str(space_gained) + "%")

from google.colab import drive
drive.mount('/content/drive')